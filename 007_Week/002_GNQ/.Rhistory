TAX + PTRATIO + B + LSTAT,data=train)
summary(linreg_transform)
predict_data_train = predict(linreg_transform,newdata = train)
predict_data_test = predict(linreg_transform,newdata = test)
regr.eval(train$MEDV,exp(predict_data_train))
regr.eval(test$MEDV,exp(predict_data_test))
housing_data$Crimerate<-NA
for (i in 1:nrow(housing_data)){
if (housing_data$CRIM[i]>=5){
housing_data$Crimerate[i]="High"
}
else {
housing_data$Crimerate[i]="Low"
}
}
table(housing_data$CRIM)
str(housing_data)
housing_data$Crimerate = as.factor(housing_data$Crimerate)
train = housing_data[intrain,]
test  = housing_data[-intrain,]
linreg_transform = lm(formula = log(MEDV)~Crimerate + ZN + CHAS + NOX + RM + DIS + RAD +
TAX + PTRATIO + B + LSTAT,data=train)
summary(linreg_transform)
predict_data_train = predict(linreg_transform,newdata = train)
predict_data_test = predict(linreg_transform,newdata = test)
regr.eval(train$MEDV,exp(predict_data_train))
regr.eval(test$MEDV,exp(predict_data_test))
str(housing_data)
table(housing_data$AGE)
table(housing_data$DIS)
table(housing_data$RAD)
housing_data$Crimerate = as.factor(housing_data$RAD)
train = housing_data[intrain,]
test  = housing_data[-intrain,]
linreg_transform = lm(formula = log(MEDV)~CRIM + ZN + CHAS + NOX + RM + DIS + RAD +
TAX + PTRATIO + B + LSTAT,data=train)
summary(linreg_transform)
predict_data_train = predict(linreg_transform,newdata = train)
predict_data_test = predict(linreg_transform,newdata = test)
regr.eval(train$MEDV,exp(predict_data_train))
regr.eval(test$MEDV,exp(predict_data_test))
housing_data$Crimerate = as.numeric(housing_data$RAD)
train = housing_data[intrain,]
test  = housing_data[-intrain,]
linreg_transform = lm(formula = log(MEDV)~CRIM + ZN + CHAS + NOX + RM + DIS + RAD +
TAX + PTRATIO + B + LSTAT,data=train)
summary(linreg_transform)
predict_data_train = predict(linreg_transform,newdata = train)
predict_data_test = predict(linreg_transform,newdata = test)
regr.eval(train$MEDV,exp(predict_data_train))
regr.eval(test$MEDV,exp(predict_data_test))
table(housing_data$TAX)
vif(linreg_transform)
library(car)
vif(linreg_transform)
table(housing_data$TAX)
str(housing_data)
table(housing_data$PTRATIO)
table(housing_data$B)
table(housing_data$LSTAT)
data.frame(actual = train$MEDV,predicted=exp(predict_data_train))
housing_data[which(rownames(housing_data)%in%c(413,373)),]
housing_data[!which(rownames(housing_data)%in%c(413,373)),]
which(rownames(housing_data)%in%c(413,373))
housing_data[-which(rownames(housing_data)%in%c(413,373)),]
housing_data = housing_data[-which(rownames(housing_data)%in%c(413,373)),]
train = housing_data[intrain,]
test  = housing_data[-intrain,]
linreg_transform = lm(formula = log(MEDV)~CRIM + ZN + CHAS + NOX + RM + DIS + RAD +
TAX + PTRATIO + B + LSTAT,data=train)
library(car)
vif(linreg_transform)
summary(linreg_transform)
predict_data_train = predict(linreg_transform,newdata = train)
predict_data_test = predict(linreg_transform,newdata = test)
regr.eval(train$MEDV,exp(predict_data_train))
regr.eval(test$MEDV,exp(predict_data_test))
plot(linreg_transform)
table(housing_data$LSTAT)
remove(list=ls())
titanic = read.csv("/Users/suresh/Desktop/Kaggle/Titanic Machine Learning from Disaster/train.csv",header = T,na.strings="")
sum(is.na(titanic))
str(titanic)
titanic = titanic[,-1]
titanic = titanic[,-which(colnames(titanic)=="Name")]
titanic = titanic[,-which(colnames(titanic)=="Ticket")]
nrow(titanic)
titanic$AgeGroup = NA
for i in 1:nrow(titanic){
if titanic$Age[i]<15{
titanic$AgeGroup[i]="Child"
}
else if titanic$Age[i]>=15 & titanic$Age[i]<30{
titanic$AgeGroup[i]="Youngster"
}
else if titanic$Age[i]>=30 & titanic$Age[i]<50{
titanic$AgeGroup[i]="Middle Age"
}
else {
titanic$AgeGroup[i]="Oldster"
}
}
for i in 1:nrow(titanic){
if titanic$Age[i]<15{
titanic$AgeGroup[i]="Child"
}
else if titanic$Age[i]>=15 & titanic$Age[i]<30{
titanic$AgeGroup[i]="Youngster"
}
else if titanic$Age[i]>=30 & titanic$Age[i]<50{
titanic$AgeGroup[i]="Middle Age"
}
else {
titanic$AgeGroup[i]="Oldster"
}
}
for (i in 1:nrow(titanic)){
if (titanic$Age[i]<15){
titanic$AgeGroup[i]="Child"
}
else if (titanic$Age[i]>=15 & titanic$Age[i]<30){
titanic$AgeGroup[i]="Youngster"
}
else if (titanic$Age[i]>=30 & titanic$Age[i]<50){
titanic$AgeGroup[i]="Middle Age"
}
else {
titanic$AgeGroup[i]="Oldster"
}
}
str(titanic)
table(titanic$Survived)
table(titanic$Survived,titanic$Pclass)
table(titanic$Name)
table(titanic$Sex)
table(titanic$Age)
table(titanic$SibSp)
table(titanic$Parch)
table(titanic$Ticket)
table(titanic$Fare)
table(titanic$Cabin)
table(titanic$Embarked)
rem_na = function(x){
(sum(is.na(x))/length(x))*100
}
sum(is.na(titanic))
titanic = read.csv("/Users/suresh/Desktop/Kaggle/Titanic Machine Learning from Disaster/train.csv",header = T,na.strings="")
sum(is.na(titanic))
titanic = titanic[,-1]
titanic = titanic[,-which(colnames(titanic)=="Name")]
titanic = titanic[,-which(colnames(titanic)=="Ticket")]
apply(titanic,2,function(x){sum(is.na(x))})
rem_na = function(x){
(sum(is.na(x))/length(x))*100
}
titanic_col_rem = titanic[,!apply(titanic,2,rem_na)>30]
titanic_col_rem
apply(titanic,2,rem_na)>30
titanic = read.csv("/Users/suresh/Desktop/Kaggle/Titanic Machine Learning from Disaster/train.csv",header = T,na.strings="")
sum(is.na(titanic))
str(titanic)
titanic = titanic[,-1]
titanic = titanic[,-which(colnames(titanic)=="Name")]
titanic = titanic[,-which(colnames(titanic)=="Ticket")]
apply(titanic,2,function(x){sum(is.na(x))})
apply(titanic,2,rem_na)>30
clean_data = knnImputation(titanic_col_rem,5)
str(clean_data)
clean_data$AgeGroup = NA
for (i in 1:nrow(clean_data)){
if (clean_data$Age[i]<15){
clean_data$AgeGroup[i]="Child"
}
else if (clean_data$Age[i]>=15 & clean_data$Age[i]<30){
clean_data$AgeGroup[i]="Youngster"
}
else if (clean_data$Age[i]>=30 & clean_data$Age[i]<50){
clean_data$AgeGroup[i]="Middle Age"
}
else {
clean_data$AgeGroup[i]="Oldster"
}
}
str(clean_data)
library(caret)
set.seed(107)
intrain = createDataPartition(clean_data$Survived,p=0.7,list=F)
train = clean_data[intrain,]
validation = clean_data[-intrain,]
logreg = glm(Survived~.,data=train,family=binomial)
summary(logreg)
predict_train = predict(logreg,newdata= train,type= 'response')
predict_train_cla = ifelse(predict_train<0.5,0,1)
naive_results = table(train$Survived,predict_train_cla)
accuracy = sum(diag(naive_results))/sum(naive_results)
accuracy
prob = prediction(predict_train,train$Survived)
library(ROCR)
prob = prediction(predict_train,train$Survived)
accerr = performance(prob,"acc","err")
cutoffs = data.frame(cut=accerr@alpha.values[[1]],err=accerr@x.values[[1]],acc=accerr@y.values[[1]])
head(cutoffs[order(cutoffs$acc,decreasing = T),])
plot(accerr,colorize=T,print.cutoffs.at=seq(0,1,by=.1),text.adj=c(-0.2,1.7))
plot(accerr,colorize=T,print.cutoffs.at=seq(0,1,by=.1),text.adj=c(-0.2,1.7))
par(mfrow=c(2,2))
plot(accerr,colorize=T,print.cutoffs.at=seq(0,1,by=.1),text.adj=c(-0.2,1.7))
par(mfrow=c(1,1))
plot(accerr,colorize=T,print.cutoffs.at=seq(0,1,by=.1),text.adj=c(-0.2,1.7))
cutoffs = data.frame(cut=tprfpr@alpha.values[[1]],err=tprfpr@x.values[[1]],acc=tprfpr@y.values[[1]])
tprfpr = performance(prob,"tpr","fpr")
cutoffs = data.frame(cut=tprfpr@alpha.values[[1]],err=tprfpr@x.values[[1]],acc=tprfpr@y.values[[1]])
plot(tprfpr,colorize=T,print.cutoffs.at=seq(0,1,by=.1),text.adj=c(-0.2,1.7))
titanic = read.csv("/Users/suresh/Desktop/Kaggle/Titanic Machine Learning from Disaster/train.csv",header = T,na.strings="")
sum(is.na(titanic))
str(titanic)
titanic = titanic[,-1]
titanic = titanic[,-which(colnames(titanic)=="Name")]
titanic = titanic[,-which(colnames(titanic)=="Ticket")]
apply(titanic,2,function(x){sum(is.na(x))})
clean_data = knnImputation(titanic_col_rem,5)
str(clean_data)
clean_data$AgeGroup = NA
for (i in 1:nrow(clean_data)){
if (clean_data$Age[i]<15){
clean_data$AgeGroup[i]="Child"
}
else if (clean_data$Age[i]>=15 & clean_data$Age[i]<30){
clean_data$AgeGroup[i]="Youngster"
}
else if (clean_data$Age[i]>=30 & clean_data$Age[i]<50){
clean_data$AgeGroup[i]="Middle Age"
}
else {
clean_data$AgeGroup[i]="Oldster"
}
}
str(clean_data)
library(caret)
set.seed(107)
intrain = createDataPartition(clean_data$Survived,p=0.7,list=F)
train = clean_data[intrain,]
validation = clean_data[-intrain,]
logreg = glm(Survived~.,data=train,family=binomial)
summary(logreg)
predict_train = predict(logreg,newdata= train,type= 'response')
predict_train_cla = ifelse(predict_train<0.5,0,1)
naive_results = table(train$Survived,predict_train_cla)
accuracy = sum(diag(naive_results))/sum(naive_results)
accuracy
library(ROCR)
prob = prediction(predict_train,train$Survived)
tprfpr = performance(prob,"tpr","fpr")
cutoffs = data.frame(cut=tprfpr@alpha.values[[1]],err=tprfpr@x.values[[1]],acc=tprfpr@y.values[[1]])
head(cutoffs[order(cutoffs$acc,decreasing = T),])
tprfpr
tprfpr@x.name
tprfpr = performance(prob,"tpr","fpr")
cutoffs = data.frame(cut=tprfpr@alpha.values[[1]],fpr=tprfpr@x.values[[1]],tpr=tprfpr@y.values[[1]])
head(cutoffs[order(cutoffs$tpr,decreasing = T),])
par(mfrow=c(1,1))
plot(tprfpr,colorize=T,print.cutoffs.at=seq(0,1,by=.1),text.adj=c(-0.2,1.7))
cutoffs[cutoffs$fpr<0.4,]
cutoffs[order(cutoffs$tpr,decreasing = T) cutoffs$fpr<0.4,]
cutoffs[cutoffs$fpr<0.4,][order(cutoffs$tpr,decreasing = T),]
cutoffs[cutoffs$fpr<0.4,][order(cutoffs$fpr,decreasing = T),]
head(cutoffs[cutoffs$fpr<0.4,][order(cutoffs$fpr,decreasing = T),])
cutoffs[cutoffs$fpr<0.4,]
cutoffs[cutoffs$fpr=0.4,]
cutoffs[cutoffs$fpr==0.4,]
cutoffs[cutoffs$fpr<=0.4,]
predict_train_cla = ifelse(predict_train<0.2,0,1)
naive_results = table(train$Survived,predict_train_cla)
accuracy = sum(diag(naive_results))/sum(naive_results)
accuracy
predict_train_cla = ifelse(predict_train<0.5,0,1)
naive_results = table(train$Survived,predict_train_cla)
accuracy = sum(diag(naive_results))/sum(naive_results)
accuracy
naive_results
predict_train_cla = ifelse(predict_train<0.2,0,1)
naive_results = table(train$Survived,predict_train_cla)
accuracy = sum(diag(naive_results))/sum(naive_results)
accuracy
stepout = stepAIC(logreg,direction = 'both')
summary(stepout)
predict_train_step = predict(stepout,newdata= train,type= 'response')
predict_train_step_cla = ifelse(predict_train_step<0.5,0,1)
stepaic_results = table(train$Survived,predict_train_step_cla)
accuracy_step = sum(diag(naive_results))/sum(naive_results)
accuracy_step
prob_step = prediction(predict_train_step,train$Survived)
tprfpr_step = performance(prob_step,"tpr","fpr")
tnrfnr_step = performance(prob_step,"tnr","fnr")
cutoffs_step = data.frame(cut = tprfpr_step@alpha.values[[1]],fpr = tprfpr_step@x.values[[1]],tpr = tprfpr_step@y.values[[1]])
plot(tprfpr_step,colorize=T,print.cutoffs.at=seq(0,1,by=.1),text.adj=c(-0.2,1.7))
tprfpr_step = performance(prob_step,"tpr","fpr")
prob_step = prediction(predict_train_step,train$Survived)
predict_train_step = predict(stepout,newdata= train,type= 'response')
stepout = stepAIC(logreg,direction = 'both')
library(MASS)
stepout = stepAIC(logreg,direction = 'both')
summary(stepout)
summary(logreg)
predict_train_step = predict(stepout,newdata= train,type= 'response')
predict_train_step_cla = ifelse(predict_train_step<0.5,0,1)
stepaic_results = table(train$Survived,predict_train_step_cla)
accuracy_step = sum(diag(naive_results))/sum(naive_results)
accuracy_step
prob_step = prediction(predict_train_step,train$Survived)
tprfpr_step = performance(prob_step,"tpr","fpr")
tnrfnr_step = performance(prob_step,"tnr","fnr")
cutoffs_step = data.frame(cut = tprfpr_step@alpha.values[[1]],fpr = tprfpr_step@x.values[[1]],tpr = tprfpr_step@y.values[[1]])
plot(tprfpr_step,colorize=T,print.cutoffs.at=seq(0,1,by=.1),text.adj=c(-0.2,1.7))
predict_train_step_cla = ifelse(predict_train_step<0.1,0,1)
stepaic_results = table(train$Survived,predict_train_step_cla)
accuracy_step = sum(diag(naive_results))/sum(naive_results)
accuracy_step
stepaic_results
accuracy
predict_train_cla = ifelse(predict_train<0.5,0,1)
naive_results = table(train$Survived,predict_train_cla)
accuracy = sum(diag(naive_results))/sum(naive_results)
accuracy
str(titanic)
str(clean_data)
clean_data$AgeGroup = NA
for (i in 1:nrow(clean_data)){
if (clean_data$Age[i]<15){
clean_data$AgeGroup[i]="1"
}
else if (clean_data$Age[i]>=15 & clean_data$Age[i]<30){
clean_data$AgeGroup[i]="2"
}
else if (clean_data$Age[i]>=30 & clean_data$Age[i]<50){
clean_data$AgeGroup[i]="3"
}
else {
clean_data$AgeGroup[i]="4"
}
}
str(clean_data)
table (clean_data)
clean_data$AgeGroup = NA
for (i in 1:nrow(clean_data)){
if (clean_data$Age[i]<15){
clean_data$AgeGroup[i]=1
}
else if (clean_data$Age[i]>=15 & clean_data$Age[i]<30){
clean_data$AgeGroup[i]=2
}
else if (clean_data$Age[i]>=30 & clean_data$Age[i]<50){
clean_data$AgeGroup[i]=3
}
else {
clean_data$AgeGroup[i]=4
}
}
str(clean_data)
for (i in 1:nrow(clean_data)){
if (clean_data$Age[i]<15){
clean_data$AgeGroup[i]=1
}
else if (clean_data$Age[i]>=15 & clean_data$Age[i]<30){
clean_data$AgeGroup[i]=2
}
else if (clean_data$Age[i]>=30 & clean_data$Age[i]<50){
clean_data$AgeGroup[i]=3
else {
}
clean_data$AgeGroup[i]=4
}
}
str(clean_data)
str(clean_data)
clean_data$AgeGroup = NA
for (i in 1:nrow(clean_data)){
if (clean_data$Age[i]<15){
clean_data$AgeGroup[i]=1
}
else if (clean_data$Age[i]>=15 & clean_data$Age[i]<30){
clean_data$AgeGroup[i]=2
}
else if (clean_data$Age[i]>=30 & clean_data$Age[i]<50){
clean_data$AgeGroup[i]=3
}
else {
clean_data$AgeGroup[i]=4
}
}
str(clean_data)
table (clean_data)
table (clean_data#)
table (clean_data$AgeGroup)
str(clean_data)
table (clean_data$AgeGroup)
library(caret)
set.seed(107)
str(clean_data)
table (clean_data$AgeGroup)
clean_data$AgeGroup+clean_data$Pclass
as.character(clean_data$AgeGroup)
as.character(clean_data$AgeGroup)+as.character(clean_data$Pclass)
as.character(clean_data$Pclass)
c(as.character(clean_data$AgeGroup),as.character(clean_data$Pclass))
plot(clean_data$Age,clean_data$Survived)
remove(list=ls())
cereals = read.csv("/Users/suresh/Desktop/Insofe/007_Week/Machine Learning Clustering/Cereals.csv",header=T)
cereals = read.csv("/Users/suresh/Desktop/Insofe/007_Week/001_Machine Learning Clustering/Cereals.csv",header=T)
str(cereals)
table(cereals$shelf)
apply(cereals,2,FUN=function(x){sum(is.na(x))})
cereals$shelf = as.factor(cereals$shelf)
apply(cereals,2,FUN=function(x){sum(is.na(x))})
cereals = knnImputation(cereals,5)
library(vegan)
cereals[,sapply(cereals,is.numeric)] = decostand(cereals[,sapply(cereals,is.numeric)],'standardize')
fit<-kmeans(cereals[,sapply(cereals,is.numeric)],centers=5)
summary(fit)
fit
2/5
2/3
10/9
install.packages("arules")
library("arules")
read.csv("/Users/suresh/Desktop/Insofe/007_Week/002_ML Rules/Transactions.csv")
data = read.csv("/Users/suresh/Desktop/Insofe/007_Week/002_ML Rules/Transactions.csv")
data = read.transactions("/Users/suresh/Desktop/Insofe/007_Week/002_ML Rules/Transactions.csv")
data
inspect(data)
trans = read.transactions(file="/Users/suresh/Desktop/Insofe/007_Week/002_ML Rules/Transactions.csv", rm.duplicates= FALSE,format="single",sep=",",cols =c(1,2))
inspect(trans)
trans
image(trans)
itemFrequency(trans)
itemFrequencyPlot(trans)
trans = read.transactions(file="/Users/suresh/Desktop/Insofe/007_Week/002_ML Rules/Transactions.csv", rm.duplicates= FALSE,format="basket",sep=",",cols =c(1,2))
inspect(trans)
trans = read.transactions(file="/Users/suresh/Desktop/Insofe/007_Week/002_ML Rules/Transactions.csv", rm.duplicates= FALSE,format="single",sep=",",cols =c(1,2))
inspect(trans)
rules <- apriori(trans,parameter = list(sup = 0.5, conf = 0.6,target="rules"))
summary(rules)
rules <- apriori(trans,parameter = list(sup = 0.2, conf = 0.6,target="rules"))
summary(rules)
inspect(trans)
itemFrequency(trans)
itemFrequencyPlot(trans)
image(trans)
summary(rules)
summary(trans)
inspect(rules)
summary(rules)
inspect(rules)
inspect(trans)
rules <- apriori(trans,parameter = list(sup = 0.2, conf = 0.5,target="rules"))
summary(rules)
inspect(rules)
inspect(trans)
summary(trans)
summary(rules)
inspect(rules)
rules <- apriori(trans,parameter = list(sup = 0.2, conf = 0.6,target="rules"))
summary(rules)
inspect(rules)
inspect(rules)
inspect(trans)
summary(trans)
sort(rules, by = c("confidence", "support")) head(as(top_rules, "data.frame"), n=5)
sort(rules, by = c("confidence", "support"))
top_rules = sort(rules, by = c("confidence", "support"))
top_rules
inspect(top_rules)
head(as(top_rules, "data.frame"), n=5)
rules_by_conf = rules[sort(rules, by = "confidence", order = TRUE)]
rules_by_conf
rules_by_conf = as(rules_by_conf,"data.frame")
rules_by_conf
inspect(top_rules)
head(as(top_rules, "data.frame"), n=5)
top_rules = sort(rules, by = c("support","confidence"))
head(as(top_rules, "data.frame"), n=5)
top_rules = sort(rules, by = c("confidence","support"),decreasing = TRUE)
inspect(top_rules)
head(as(top_rules, "data.frame"), n=5)
top_rules = sort(rules, by = c("lift","confidence","support"),decreasing = TRUE)
inspect(top_rules)
head(as(top_rules, "data.frame"), n=5)
attach(mtcars)
dim(mtcars)
str(mtcars)
sum(is.na(data))
sum(is.na(mtcars))
library(vegan)
data <- mtcars
dim(mtcars)
dim(data)
str(data)
sum(is.na(data))
library(vegan)
data2 <- decostand(data,method="standardize")
d<-dist(data2,method="euclarian")
d<-dist(data2,method="euclidean")
as.matrix(d)
distances<-as.matrix(d)
View(distances)
data
fit<-hclust(d,method="single")
plot(fit)
fit$merge
fit$height
View(distances)
fit<-hclust(d,method="ward")
plot(fit)
